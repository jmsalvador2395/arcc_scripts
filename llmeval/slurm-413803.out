loaded anaconda
loaded cuda
activated conda environment
changed directory to /home/jsalvador/projects/llmeval
[[33mINFO[0m] running infill_solve using meta-llama/Llama-3.3-70B-Instruct
[[33mINFO[0m] fetching subsample IDs
counting prompt variations
[[33mINFO[0m] unique template_name query took 2101.17 seconds
[[33mINFO[0m] unique template_id query took 1271.97 seconds
[[33mINFO[0m] unique sys_id query took 37.97 seconds
fitb_l0, tids: 1, sids: 6
[[33mINFO[0m] counting samples from each query
[[33mINFO[0m] counting samples took 0.16 seconds
[[33mINFO[0m] unique template_id query took 39.14 seconds
[[33mINFO[0m] unique sys_id query took 37.83 seconds
fitb_l1, tids: 4, sids: 6
[[33mINFO[0m] counting samples from each query
[[33mINFO[0m] counting samples took 0.07 seconds
[[33mINFO[0m] unique template_id query took 38.70 seconds
[[33mINFO[0m] unique sys_id query took 37.83 seconds
fitb_l2, tids: 5, sids: 6
[[33mINFO[0m] counting samples from each query
[[33mINFO[0m] counting samples took 0.09 seconds
[[33mINFO[0m] unique template_id query took 37.98 seconds
[[33mINFO[0m] unique sys_id query took 38.04 seconds
fitb_l3, tids: 5, sids: 6
[[33mINFO[0m] counting samples from each query
[[33mINFO[0m] counting samples took 0.09 seconds
[[33mINFO[0m] unique template_id query took 39.30 seconds
[[33mINFO[0m] unique sys_id query took 37.91 seconds
fitb_l4, tids: 6, sids: 6
[[33mINFO[0m] counting samples from each query
[[33mINFO[0m] counting samples took 0.11 seconds
[[33mINFO[0m] batch_size: 1000, limit: 1000, N: 126000, N_batch: 126
creating generator function
[[33mINFO[0m] loading model: meta-llama/Llama-3.3-70B-Instruct
WARNING 01-25 17:16:20 config.py:319] bitsandbytes quantization is not fully optimized yet. The speed can be slower than non-quantized models.
WARNING 01-25 17:16:20 arg_utils.py:930] Chunked prefill is enabled by default for models with max_model_len > 32K. Currently, chunked prefill might not work with some features or models. If you encounter any issues, please disable chunked prefill by setting --enable-chunked-prefill=False.
INFO 01-25 17:16:20 config.py:1010] Chunked prefill is enabled with max_num_batched_tokens=512.
WARNING 01-25 17:16:20 config.py:389] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
2025-01-25 17:16:40,761	INFO worker.py:1821 -- Started a local Ray instance.
INFO 01-25 17:17:01 llm_engine.py:226] Initializing an LLM engine (v0.6.1.dev238+ge2c6e0a82) with config: model='meta-llama/Llama-3.3-70B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.3-70B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=50000, download_dir='/lustre/fs1/home/jsalvador/projects/llmeval/data/llm_cache', load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=True, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=1737843380, served_model_name=meta-llama/Llama-3.3-70B-Instruct, use_v2_block_manager=False, num_scheduler_steps=1, multi_step_stream_outputs=False, enable_prefix_caching=False, use_async_output_proc=False, use_cached_outputs=False, mm_processor_kwargs=None)
INFO 01-25 17:17:02 ray_gpu_executor.py:134] use_ray_spmd_worker: False
INFO 01-25 17:18:01 utils.py:992] Found nccl from library libnccl.so.2
INFO 01-25 17:18:01 pynccl.py:63] vLLM is using nccl==2.20.5
[36m(RayWorkerWrapper pid=19192)[0m INFO 01-25 17:18:01 utils.py:992] Found nccl from library libnccl.so.2
[36m(RayWorkerWrapper pid=19192)[0m INFO 01-25 17:18:01 pynccl.py:63] vLLM is using nccl==2.20.5
INFO 01-25 17:18:04 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /home/jsalvador/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
[36m(RayWorkerWrapper pid=19192)[0m INFO 01-25 17:18:04 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /home/jsalvador/.cache/vllm/gpu_p2p_access_cache_for_0,1.json
INFO 01-25 17:18:04 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x1490f4cd22d0>, local_subscribe_port=32945, remote_subscribe_port=None)
INFO 01-25 17:18:04 model_runner.py:1014] Starting to load model meta-llama/Llama-3.3-70B-Instruct...
[36m(RayWorkerWrapper pid=19192)[0m INFO 01-25 17:18:04 model_runner.py:1014] Starting to load model meta-llama/Llama-3.3-70B-Instruct...
INFO 01-25 17:18:09 loader.py:1014] Loading weights with BitsAndBytes quantization.  May take a while ...
[36m(RayWorkerWrapper pid=19192)[0m INFO 01-25 17:18:09 loader.py:1014] Loading weights with BitsAndBytes quantization.  May take a while ...
INFO 01-25 17:18:09 weight_utils.py:242] Using model weights format ['*.safetensors']
[36m(RayWorkerWrapper pid=19192)[0m INFO 01-25 17:18:09 weight_utils.py:242] Using model weights format ['*.safetensors']
Loading safetensors checkpoint shards:   0% Completed | 0/30 [00:00<?, ?it/s]
Loading safetensors checkpoint shards:   3% Completed | 1/30 [00:07<03:44,  7.76s/it]
Loading safetensors checkpoint shards:   7% Completed | 2/30 [00:16<04:00,  8.59s/it]
Loading safetensors checkpoint shards:  10% Completed | 3/30 [00:22<03:19,  7.39s/it]
Loading safetensors checkpoint shards:  13% Completed | 4/30 [00:28<02:53,  6.69s/it]
Loading safetensors checkpoint shards:  17% Completed | 5/30 [00:33<02:30,  6.00s/it]
Loading safetensors checkpoint shards:  20% Completed | 6/30 [00:38<02:20,  5.84s/it]
Loading safetensors checkpoint shards:  23% Completed | 7/30 [00:44<02:14,  5.84s/it]
Loading safetensors checkpoint shards:  27% Completed | 8/30 [00:51<02:17,  6.23s/it]
Loading safetensors checkpoint shards:  30% Completed | 9/30 [01:01<02:36,  7.47s/it]
Loading safetensors checkpoint shards:  33% Completed | 10/30 [01:08<02:24,  7.21s/it]
Loading safetensors checkpoint shards:  37% Completed | 11/30 [01:13<02:03,  6.52s/it]
Loading safetensors checkpoint shards:  40% Completed | 12/30 [01:20<02:00,  6.72s/it]
Loading safetensors checkpoint shards:  43% Completed | 13/30 [01:26<01:47,  6.32s/it]
Loading safetensors checkpoint shards:  47% Completed | 14/30 [01:35<01:56,  7.31s/it]
Loading safetensors checkpoint shards:  50% Completed | 15/30 [01:42<01:48,  7.22s/it]
Loading safetensors checkpoint shards:  53% Completed | 16/30 [01:49<01:39,  7.10s/it]
Loading safetensors checkpoint shards:  57% Completed | 17/30 [01:56<01:32,  7.08s/it]
Loading safetensors checkpoint shards:  60% Completed | 18/30 [02:02<01:21,  6.76s/it]
Loading safetensors checkpoint shards:  63% Completed | 19/30 [02:10<01:18,  7.13s/it]
Loading safetensors checkpoint shards:  67% Completed | 20/30 [02:16<01:07,  6.77s/it]
Loading safetensors checkpoint shards:  70% Completed | 21/30 [02:24<01:03,  7.03s/it]
Loading safetensors checkpoint shards:  73% Completed | 22/30 [02:30<00:54,  6.81s/it]
Loading safetensors checkpoint shards:  77% Completed | 23/30 [02:35<00:44,  6.35s/it]
Loading safetensors checkpoint shards:  80% Completed | 24/30 [02:41<00:37,  6.21s/it]
Loading safetensors checkpoint shards:  83% Completed | 25/30 [02:49<00:34,  6.83s/it]
Loading safetensors checkpoint shards:  87% Completed | 26/30 [02:58<00:29,  7.39s/it]
Loading safetensors checkpoint shards:  90% Completed | 27/30 [03:06<00:22,  7.45s/it]
Loading safetensors checkpoint shards:  93% Completed | 28/30 [03:11<00:13,  6.98s/it]
Loading safetensors checkpoint shards:  97% Completed | 29/30 [03:17<00:06,  6.50s/it]
Loading safetensors checkpoint shards: 100% Completed | 30/30 [03:25<00:00,  6.85s/it]
Loading safetensors checkpoint shards: 100% Completed | 30/30 [03:25<00:00,  6.84s/it]

[36m(RayWorkerWrapper pid=19192)[0m INFO 01-25 17:21:35 model_runner.py:1025] Loading model weights took 18.4395 GB
INFO 01-25 17:21:37 model_runner.py:1025] Loading model weights took 18.4395 GB
INFO 01-25 17:21:44 distributed_gpu_executor.py:57] # GPU blocks: 20819, # CPU blocks: 1638
[[33mINFO[0m] begin collecting responses
generating responses:   0%|          | 0/378 [00:00<?, ?it/s][36m(RayWorkerWrapper pid=19192)[0m [rank1]:[E125 18:01:32.453730052 ProcessGroupNCCL.cpp:1515] [PG 3 Rank 1] Process group watchdog thread terminated with exception: CUDA error: uncorrectable ECC error encountered
[36m(RayWorkerWrapper pid=19192)[0m CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(RayWorkerWrapper pid=19192)[0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(RayWorkerWrapper pid=19192)[0m Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(RayWorkerWrapper pid=19192)[0m 
[36m(RayWorkerWrapper pid=19192)[0m Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
[36m(RayWorkerWrapper pid=19192)[0m frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14ace82dbf86 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libc10.so)
[36m(RayWorkerWrapper pid=19192)[0m frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x14ace828ad10 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libc10.so)
[36m(RayWorkerWrapper pid=19192)[0m frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x14ace83b6f08 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libc10_cuda.so)
[36m(RayWorkerWrapper pid=19192)[0m frame #3: c10d::ProcessGroupNCCL::WorkNCCL::finishedGPUExecutionInternal() const + 0x56 (0x14ac2fd763e6 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
[36m(RayWorkerWrapper pid=19192)[0m frame #4: c10d::ProcessGroupNCCL::WorkNCCL::isCompleted() + 0xa0 (0x14ac2fd7b600 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
[36m(RayWorkerWrapper pid=19192)[0m frame #5: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1da (0x14ac2fd822ba in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
[36m(RayWorkerWrapper pid=19192)[0m frame #6: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x14ac2fd846fc in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
[36m(RayWorkerWrapper pid=19192)[0m frame #7: <unknown function> + 0xdbbf4 (0x14d2fb20bbf4 in /lustre/fs1/home/jsalvador/.conda/envs/llmeval/bin/../lib/libstdc++.so.6)
[36m(RayWorkerWrapper pid=19192)[0m frame #8: <unknown function> + 0x81cf (0x14d30ad4d1cf in /lib64/libpthread.so.0)
[36m(RayWorkerWrapper pid=19192)[0m frame #9: clone + 0x43 (0x14d30a22ee73 in /lib64/libc.so.6)
[36m(RayWorkerWrapper pid=19192)[0m 
[36m(RayWorkerWrapper pid=19192)[0m [2025-01-25 18:01:32,640 E 19192 23128] logging.cc:111: Unhandled exception: N3c1016DistBackendErrorE. what(): [PG 3 Rank 1] Process group watchdog thread terminated with exception: CUDA error: uncorrectable ECC error encountered
[36m(RayWorkerWrapper pid=19192)[0m CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[36m(RayWorkerWrapper pid=19192)[0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[36m(RayWorkerWrapper pid=19192)[0m Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[36m(RayWorkerWrapper pid=19192)[0m 
[36m(RayWorkerWrapper pid=19192)[0m Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:43 (most recent call first):
[36m(RayWorkerWrapper pid=19192)[0m frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14ace82dbf86 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libc10.so)
[36m(RayWorkerWrapper pid=19192)[0m frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x14ace828ad10 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libc10.so)
[36m(RayWorkerWrapper pid=19192)[0m frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x14ace83b6f08 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libc10_cuda.so)
[36m(RayWorkerWrapper pid=19192)[0m frame #3: c10d::ProcessGroupNCCL::WorkNCCL::finishedGPUExecutionInternal() const + 0x56 (0x14ac2fd763e6 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
[36m(RayWorkerWrapper pid=19192)[0m frame #4: c10d::ProcessGroupNCCL::WorkNCCL::isCompleted() + 0xa0 (0x14ac2fd7b600 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
[36m(RayWorkerWrapper pid=19192)[0m frame #5: c10d::ProcessGroupNCCL::watchdogHandler() + 0x1da (0x14ac2fd822ba in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
[36m(RayWorkerWrapper pid=19192)[0m frame #6: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x14ac2fd846fc in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
[36m(RayWorkerWrapper pid=19192)[0m frame #7: <unknown function> + 0xdbbf4 (0x14d2fb20bbf4 in /lustre/fs1/home/jsalvador/.conda/envs/llmeval/bin/../lib/libstdc++.so.6)
[36m(RayWorkerWrapper pid=19192)[0m frame #8: <unknown function> + 0x81cf (0x14d30ad4d1cf in /lib64/libpthread.so.0)
[36m(RayWorkerWrapper pid=19192)[0m frame #9: clone + 0x43 (0x14d30a22ee73 in /lib64/libc.so.6)
[36m(RayWorkerWrapper pid=19192)[0m 
[36m(RayWorkerWrapper pid=19192)[0m Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1521 (most recent call first):
[36m(RayWorkerWrapper pid=19192)[0m frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14ace82dbf86 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libc10.so)
[36m(RayWorkerWrapper pid=19192)[0m frame #1: <unknown function> + 0xe5aa84 (0x14ac2fa0da84 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
[36m(RayWorkerWrapper pid=19192)[0m frame #2: <unknown function> + 0xdbbf4 (0x14d2fb20bbf4 in /lustre/fs1/home/jsalvador/.conda/envs/llmeval/bin/../lib/libstdc++.so.6)
[36m(RayWorkerWrapper pid=19192)[0m frame #3: <unknown function> + 0x81cf (0x14d30ad4d1cf in /lib64/libpthread.so.0)
[36m(RayWorkerWrapper pid=19192)[0m frame #4: clone + 0x43 (0x14d30a22ee73 in /lib64/libc.so.6)
[36m(RayWorkerWrapper pid=19192)[0m 
[36m(RayWorkerWrapper pid=19192)[0m [2025-01-25 18:01:33,451 E 19192 23128] logging.cc:118: Stack trace: 
[36m(RayWorkerWrapper pid=19192)[0m  /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/ray/_raylet.so(+0x115a17a) [0x14d2fc6b817a] ray::operator<<()
[36m(RayWorkerWrapper pid=19192)[0m /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/ray/_raylet.so(+0x115d152) [0x14d2fc6bb152] ray::TerminateHandler()
[36m(RayWorkerWrapper pid=19192)[0m /lustre/fs1/home/jsalvador/.conda/envs/llmeval/bin/../lib/libstdc++.so.6(+0xb135a) [0x14d2fb1e135a] __cxxabiv1::__terminate()
[36m(RayWorkerWrapper pid=19192)[0m /lustre/fs1/home/jsalvador/.conda/envs/llmeval/bin/../lib/libstdc++.so.6(+0xb13c5) [0x14d2fb1e13c5]
[36m(RayWorkerWrapper pid=19192)[0m /lustre/fs1/home/jsalvador/.conda/envs/llmeval/bin/../lib/libstdc++.so.6(+0xb134f) [0x14d2fb1e134f]
[36m(RayWorkerWrapper pid=19192)[0m /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so(+0xe5ab35) [0x14ac2fa0db35] c10d::ProcessGroupNCCL::ncclCommWatchdog()
[36m(RayWorkerWrapper pid=19192)[0m /lustre/fs1/home/jsalvador/.conda/envs/llmeval/bin/../lib/libstdc++.so.6(+0xdbbf4) [0x14d2fb20bbf4] execute_native_thread_routine
[36m(RayWorkerWrapper pid=19192)[0m /lib64/libpthread.so.0(+0x81cf) [0x14d30ad4d1cf] start_thread
[36m(RayWorkerWrapper pid=19192)[0m /lib64/libc.so.6(clone+0x43) [0x14d30a22ee73] clone
[36m(RayWorkerWrapper pid=19192)[0m 
[36m(RayWorkerWrapper pid=19192)[0m *** SIGABRT received at time=1737846093 on cpu 0 ***
[36m(RayWorkerWrapper pid=19192)[0m PC: @     0x14d30a243aff  (unknown)  raise
[36m(RayWorkerWrapper pid=19192)[0m     @     0x14d30ad57cf0       5072  (unknown)
[36m(RayWorkerWrapper pid=19192)[0m     @     0x14d2fb1e135a  (unknown)  __cxxabiv1::__terminate()
[36m(RayWorkerWrapper pid=19192)[0m     @     0x14d2fb1e1070  (unknown)  (unknown)
[36m(RayWorkerWrapper pid=19192)[0m [2025-01-25 18:01:33,452 E 19192 23128] logging.cc:447: *** SIGABRT received at time=1737846093 on cpu 0 ***
[36m(RayWorkerWrapper pid=19192)[0m [2025-01-25 18:01:33,452 E 19192 23128] logging.cc:447: PC: @     0x14d30a243aff  (unknown)  raise
[36m(RayWorkerWrapper pid=19192)[0m [2025-01-25 18:01:33,452 E 19192 23128] logging.cc:447:     @     0x14d30ad57cf0       5072  (unknown)
[36m(RayWorkerWrapper pid=19192)[0m [2025-01-25 18:01:33,452 E 19192 23128] logging.cc:447:     @     0x14d2fb1e135a  (unknown)  __cxxabiv1::__terminate()
[36m(RayWorkerWrapper pid=19192)[0m [2025-01-25 18:01:33,452 E 19192 23128] logging.cc:447:     @     0x14d2fb1e1070  (unknown)  (unknown)
[36m(RayWorkerWrapper pid=19192)[0m Fatal Python error: Aborted
[36m(RayWorkerWrapper pid=19192)[0m 
[36m(RayWorkerWrapper pid=19192)[0m 
[36m(RayWorkerWrapper pid=19192)[0m Extension modules: msgpack._cmsgpack, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, setproctitle, yaml._yaml, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, uvloop.loop, ray._raylet, numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, torch._C, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special
[36m(RayWorkerWrapper pid=19192)[0m , markupsafe._speedups, PIL._imaging, msgspec._core, sentencepiece._sentencepiece, PIL._imagingft
[36m(RayWorkerWrapper pid=19192)[0m , sklearn.__check_build._check_build, scipy._lib._ccallback_c, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, scipy.linalg._solve_toeplitz, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg.cython_blas, scipy.linalg._matfuncs_expm, scipy.linalg._decomp_update, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.linalg._propack._spropack, scipy.sparse.linalg._propack._dpropack, scipy.sparse.linalg._propack._cpropack, scipy.sparse.linalg._propack._zpropack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, scipy.special._ufuncs_cxx, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.special._ellip_harm_2, scipy.spatial._ckdtree, scipy._lib.messagestream, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._distance_wrap, scipy.spatial._hausdorff, scipy.spatial.transform._rotation, scipy.optimize._group_columns, scipy.optimize._trlib._trlib, scipy.optimize._lbfgsb, _moduleTNC, scipy.optimize._moduleTNC, scipy.optimize._cobyla, scipy.optimize._slsqp, scipy.optimize._minpack, scipy.optimize._lsq.givens_elimination, scipy.optimize._zeros, scipy.optimize._highs.cython.src._highs_wrapper, scipy.optimize._highs._highs_wrapper, scipy.optimize._highs.cython.src._highs_constants, scipy.optimize._highs._highs_constants, scipy.linalg._interpolative, scipy.optimize._bglu_dense, scipy.optimize._lsap, scipy.optimize._direct, scipy.integrate._odepack, scipy.integrate._quadpack, scipy.integrate._vode, scipy.integrate._dop, scipy.integrate._lsoda, scipy.interpolate._fitpack, scipy.interpolate._dfitpack, scipy.interpolate._bspl, scipy.interpolate._ppoly, scipy.interpolate.interpnd, scipy.interpolate._rbfinterp_pythran, scipy.interpolate._rgi_cython, scipy.special.cython_special, scipy.stats._stats, scipy.stats._biasedurn, scipy.stats._levy_stable.levyst, scipy.stats._stats_pythran, scipy._lib._uarray._uarray, scipy.stats._ansari_swilk_statistics, scipy.stats._sobol, scipy.stats._qmc_cy, scipy.stats._mvn, scipy.stats._rcont.rcont, scipy.stats._unuran.unuran_wrapper, scipy.ndimage._nd_image, _ni_label, scipy.ndimage._ni_label, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, sklearn.utils._isfinite, sklearn.utils.sparsefuncs_fast, sklearn.utils.murmurhash, sklearn.utils._openmp_helpers, sklearn.metrics.cluster._expected_mutual_info_fast, sklearn.preprocessing._csr_polynomial_expansion, sklearn.preprocessing._target_encoder_fast, sklearn.metrics._dist_metrics, sklearn.metrics._pairwise_distances_reduction._datasets_pair, sklearn.utils._cython_blas, sklearn.metrics._pairwise_distances_reduction._base, sklearn.metrics._pairwise_distances_reduction._middle_term_computer, sklearn.utils._heap, sklearn.utils._sorting, sklearn.metrics._pairwise_distances_reduction._argkmin, sklearn.metrics._pairwise_distances_reduction._argkmin_classmode, sklearn.utils._vector_sentinel, sklearn.metrics._pairwise_distances_reduction._radius_neighbors, sklearn.metrics._pairwise_distances_reduction._radius_neighbors_classmode, sklearn.metrics._pairwise_fast, regex._regex, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist
[36m(RayWorkerWrapper pid=19192)[0m , pyarrow._json, zmq.backend.cython._zmq (total: 194)
[rank0]:[E125 18:11:31.288083027 ProcessGroupNCCL.cpp:607] [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=897, OpType=ALLREDUCE, NumelIn=4194304, NumelOut=4194304, Timeout(ms)=600000) ran for 600085 milliseconds before timing out.
[rank0]:[E125 18:11:31.514093489 ProcessGroupNCCL.cpp:1664] [PG 3 Rank 0] Exception (either an error or timeout) detected by watchdog at work: 897, last enqueued NCCL work: 941, last completed NCCL work: 896.
[rank0]:[E125 18:11:31.514533015 ProcessGroupNCCL.cpp:1709] [PG 3 Rank 0] Timeout at NCCL work: 897, last enqueued NCCL work: 941, last completed NCCL work: 896.
[rank0]:[E125 18:11:31.514660075 ProcessGroupNCCL.cpp:621] [Rank 0] Some NCCL operations have failed or timed out. Due to the asynchronous nature of CUDA kernels, subsequent GPU operations might run on corrupted/incomplete data.
[rank0]:[E125 18:11:31.514916433 ProcessGroupNCCL.cpp:627] [Rank 0] To avoid data inconsistency, we are taking the entire process down.
[rank0]:[E125 18:11:31.551990935 ProcessGroupNCCL.cpp:1515] [PG 3 Rank 0] Process group watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=897, OpType=ALLREDUCE, NumelIn=4194304, NumelOut=4194304, Timeout(ms)=600000) ran for 600085 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14920faeaf86 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x149210de78d2 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x149210dee313 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x149210df06fc in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdbbf4 (0x1492604d1bf4 in /lustre/fs1/home/jsalvador/.conda/envs/llmeval/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x81cf (0x1492705251cf in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x14926fa06e73 in /lib64/libc.so.6)

[2025-01-25 18:11:31,443 E 18015 23127] logging.cc:111: Unhandled exception: N3c1016DistBackendErrorE. what(): [PG 3 Rank 0] Process group watchdog thread terminated with exception: [Rank 0] Watchdog caught collective operation timeout: WorkNCCL(SeqNum=897, OpType=ALLREDUCE, NumelIn=4194304, NumelOut=4194304, Timeout(ms)=600000) ran for 600085 milliseconds before timing out.
Exception raised from checkTimeout at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:609 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14920faeaf86 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10d::ProcessGroupNCCL::WorkNCCL::checkTimeout(std::optional<std::chrono::duration<long, std::ratio<1l, 1000l> > >) + 0x1d2 (0x149210de78d2 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: c10d::ProcessGroupNCCL::watchdogHandler() + 0x233 (0x149210dee313 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #3: c10d::ProcessGroupNCCL::ncclCommWatchdog() + 0x10c (0x149210df06fc in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #4: <unknown function> + 0xdbbf4 (0x1492604d1bf4 in /lustre/fs1/home/jsalvador/.conda/envs/llmeval/bin/../lib/libstdc++.so.6)
frame #5: <unknown function> + 0x81cf (0x1492705251cf in /lib64/libpthread.so.0)
frame #6: clone + 0x43 (0x14926fa06e73 in /lib64/libc.so.6)

Exception raised from ncclCommWatchdog at ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1521 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x14920faeaf86 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: <unknown function> + 0xe5aa84 (0x149210a79a84 in /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)
frame #2: <unknown function> + 0xdbbf4 (0x1492604d1bf4 in /lustre/fs1/home/jsalvador/.conda/envs/llmeval/bin/../lib/libstdc++.so.6)
frame #3: <unknown function> + 0x81cf (0x1492705251cf in /lib64/libpthread.so.0)
frame #4: clone + 0x43 (0x14926fa06e73 in /lib64/libc.so.6)

[2025-01-25 18:11:31,620 E 18015 23127] logging.cc:118: Stack trace: 
 /home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/ray/_raylet.so(+0x115a17a) [0x14926197e17a] ray::operator<<()
/home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/ray/_raylet.so(+0x115d152) [0x149261981152] ray::TerminateHandler()
/lustre/fs1/home/jsalvador/.conda/envs/llmeval/bin/../lib/libstdc++.so.6(+0xb135a) [0x1492604a735a] __cxxabiv1::__terminate()
/lustre/fs1/home/jsalvador/.conda/envs/llmeval/bin/../lib/libstdc++.so.6(+0xb13c5) [0x1492604a73c5]
/lustre/fs1/home/jsalvador/.conda/envs/llmeval/bin/../lib/libstdc++.so.6(+0xb134f) [0x1492604a734f]
/home/jsalvador/.conda/envs/llmeval/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so(+0xe5ab35) [0x149210a79b35] c10d::ProcessGroupNCCL::ncclCommWatchdog()
/lustre/fs1/home/jsalvador/.conda/envs/llmeval/bin/../lib/libstdc++.so.6(+0xdbbf4) [0x1492604d1bf4] execute_native_thread_routine
/lib64/libpthread.so.0(+0x81cf) [0x1492705251cf] start_thread
/lib64/libc.so.6(clone+0x43) [0x14926fa06e73] clone

*** SIGABRT received at time=1737846691 on cpu 0 ***
PC: @     0x14926fa1baff  (unknown)  raise
    @     0x14927052fcf0       5072  (unknown)
    @     0x1492604a735a  (unknown)  __cxxabiv1::__terminate()
    @     0x1492604a7070  (unknown)  (unknown)
[2025-01-25 18:11:31,622 E 18015 23127] logging.cc:447: *** SIGABRT received at time=1737846691 on cpu 0 ***
[2025-01-25 18:11:31,622 E 18015 23127] logging.cc:447: PC: @     0x14926fa1baff  (unknown)  raise
[2025-01-25 18:11:31,622 E 18015 23127] logging.cc:447:     @     0x14927052fcf0       5072  (unknown)
[2025-01-25 18:11:31,622 E 18015 23127] logging.cc:447:     @     0x1492604a735a  (unknown)  __cxxabiv1::__terminate()
[2025-01-25 18:11:31,622 E 18015 23127] logging.cc:447:     @     0x1492604a7070  (unknown)  (unknown)
Fatal Python error: Aborted


Extension modules: yaml._yaml, msgpack._cmsgpack, google._upb._message, psutil._psutil_linux, psutil._psutil_posix, setproctitle, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, uvloop.loop, ray._raylet, numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, torch._C, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._parquet, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, multidict._multidict, yarl._quoting_c, propcache._helpers_c, aiohttp._http_writer, aiohttp._http_parser, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, xxhash._xxhash, pyarrow._json, pyarrow._acero, pyarrow._csv, pyarrow._dataset, pyarrow._dataset_orc, pyarrow._parquet_encryption, pyarrow._dataset_parquet_encryption, pyarrow._dataset_parquet, markupsafe._speedups, PIL._imaging, msgspec._core, sentencepiece._sentencepiece, PIL._imagingft, sklearn.__check_build._check_build, scipy._lib._ccallback_c, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, scipy.linalg._solve_toeplitz, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg.cython_blas, scipy.linalg._matfuncs_expm, scipy.linalg._decomp_update, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.linalg._propack._spropack, scipy.sparse.linalg._propack._dpropack, scipy.sparse.linalg._propack._cpropack, scipy.sparse.linalg._propack._zpropack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, scipy.special._ufuncs_cxx, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.special._ellip_harm_2, scipy.spatial._ckdtree, scipy._lib.messagestream, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._distance_wrap, scipy.spatial._hausdorff, scipy.spatial.transform._rotation, scipy.optimize._group_columns, scipy.optimize._trlib._trlib, scipy.optimize._lbfgsb, _moduleTNC, scipy.optimize._moduleTNC, scipy.optimize._cobyla, scipy.optimize._slsqp, scipy.optimize._minpack, scipy.optimize._lsq.givens_elimination, scipy.optimize._zeros, scipy.optimize._highs.cython.src._highs_wrapper, scipy.optimize._highs._highs_wrapper, scipy.optimize._highs.cython.src._highs_constants, scipy.optimize._highs._highs_constants, scipy.linalg._interpolative, scipy.optimize._bglu_dense, scipy.optimize._lsap, scipy.optimize._direct, scipy.integrate._odepack, scipy.integrate._quadpack, scipy.integrate._vode, scipy.integrate._dop, scipy.integrate._lsoda, scipy.interpolate._fitpack, scipy.interpolate._dfitpack, scipy.interpolate._bspl, scipy.interpolate._ppoly, scipy.interpolate.interpnd, scipy.interpolate._rbfinterp_pythran, scipy.interpolate._rgi_cython, scipy.special.cython_special, scipy.stats._stats, scipy.stats._biasedurn, scipy.stats._levy_stable.levyst, scipy.stats._stats_pythran, scipy._lib._uarray._uarray, scipy.stats._ansari_swilk_statistics, scipy.stats._sobol, scipy.stats._qmc_cy, scipy.stats._mvn, scipy.stats._rcont.rcont, scipy.stats._unuran.unuran_wrapper, scipy.ndimage._nd_image, _ni_label, scipy.ndimage._ni_label, sklearn.utils._isfinite, sklearn.utils.sparsefuncs_fast, sklearn.utils.murmurhash, sklearn.utils._openmp_helpers, sklearn.metrics.cluster._expected_mutual_info_fast, sklearn.preprocessing._csr_polynomial_expansion, sklearn.preprocessing._target_encoder_fast, sklearn.metrics._dist_metrics, sklearn.metrics._pairwise_distances_reduction._datasets_pair, sklearn.utils._cython_blas, sklearn.metrics._pairwise_distances_reduction._base, sklearn.metrics._pairwise_distances_reduction._middle_term_computer, sklearn.utils._heap, sklearn.utils._sorting, sklearn.metrics._pairwise_distances_reduction._argkmin, sklearn.metrics._pairwise_distances_reduction._argkmin_classmode, sklearn.utils._vector_sentinel, sklearn.metrics._pairwise_distances_reduction._radius_neighbors, sklearn.metrics._pairwise_distances_reduction._radius_neighbors_classmode, sklearn.metrics._pairwise_fast, regex._regex, grpc._cython.cygrpc, sklearn.feature_extraction._hashing_fast, sklearn.utils._random, sklearn.utils._seq_dataset, sklearn.linear_model._cd_fast, _loss, sklearn._loss._loss, sklearn.utils.arrayfuncs, sklearn.svm._liblinear, sklearn.svm._libsvm, sklearn.svm._libsvm_sparse, sklearn.linear_model._sag_fast, sklearn.utils._weight_vector, sklearn.linear_model._sgd_fast, scipy.io.matlab._mio_utils, scipy.io.matlab._streams, scipy.io.matlab._mio5_utils, sklearn.datasets._svmlight_format_fast, zmq.backend.cython._zmq (total: 226)
/home/jsalvador/.conda/envs/llmeval/lib/python3.11/multiprocessing/resource_tracker.py:254: UserWarning: resource_tracker: There appear to be 1 leaked shared_memory objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
/var/spool/slurmd/job413803/slurm_script: line 9: 18015 Aborted                 (core dumped) llm_eval infill_solve -m meta-llama/Llama-3.3-70B-Instruct -p data/results/infill/20250108-222137/data.db -l 1000
